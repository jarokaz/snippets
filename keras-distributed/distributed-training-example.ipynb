{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p sample\n",
    "echo \"\" > sample/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "[(None, None, 1), (None,)] (None, None, 5)\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 100 steps\n",
      "100/100 [==============================] - 152s 2s/step - loss: 1.6452\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def main():\n",
    "    tf.compat.v1.experimental.output_all_intermediates(True)\n",
    "    seq_data = keras.Input(shape=(None, 1),  name=\"seq_data\")\n",
    "    seq_lengths = keras.Input(shape=(), name=\"seq_lengths\", dtype=tf.int32)\n",
    "\n",
    "    mask = keras.layers.Lambda(lambda x: tf.sequence_mask(x))(seq_lengths)\n",
    "    conv = layers.Conv1D(32, 3, strides=1, padding='same', activation='relu')(seq_data)\n",
    "    #rnn = layers.Bidirectional(layers.GRU(32, return_sequences=True))(conv,mask=mask)\n",
    "    rnn = layers.Bidirectional(layers.GRU(32, return_sequences=True))(conv)\n",
    "    dense = layers.Dense(5, name=\"signal_mask\")(rnn)\n",
    "    model = keras.Model(inputs=[seq_data, seq_lengths], outputs=[dense])\n",
    "    print(model.input_shape, model.output_shape)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.001),\n",
    "        loss=tf.keras.backend.sparse_categorical_crossentropy\n",
    "    )\n",
    "\n",
    "    batch_size = 1\n",
    "    time_step = 1000\n",
    "    signal_length = 1000\n",
    "    sequences = np.random.rand(batch_size, time_step, 1)\n",
    "    seq_lengths = np.array([signal_length])\n",
    "    signal_mask = np.random.randint(5, size=(1, time_step))\n",
    "    #def map_fn(a,b,c):\n",
    "    #    return ({\"seq_data\":a,\"seq_lengths\":b}, {\"signal_mask\":c})\n",
    "    #dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    #    (sequences, seq_lengths,  signal_mask)).repeat(100).batch(1).map(map_fn)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((sequences, seq_lengths),  signal_mask)).repeat(100).batch(1)\n",
    "\n",
    "    model.fit(dataset, epochs=1)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sample/model.py\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample/model.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4b8d01e9d4c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample/model.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nimport tensorflow as tf\\nfrom tensorflow.python.framework.ops import disable_eager_execution\\ndisable_eager_execution()\\nimport numpy as np\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\n\\ndef main():\\n    mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\\n                        \\n    with mirrored_strategy.scope():\\n        seq_data = keras.Input(shape=(None, 1),  name=\"seq_data\")\\n        seq_lengths = keras.Input(shape=(), name=\"seq_lengths\", dtype=tf.int32)\\n\\n        mask = keras.layers.Lambda(lambda x: tf.sequence_mask(x))(seq_lengths)\\n        conv = layers.Conv1D(32, 3, strides=1, padding=\\'same\\', activation=\\'relu\\')(seq_data)\\n        #rnn = layers.Bidirectional(layers.GRU(32, return_sequences=True))(conv,mask=mask)\\n        rnn = layers.Bidirectional(layers.GRU(32, return_sequences=True))(conv)\\n        dense = layers.Dense(5, name=\"signal_mask\")(rnn)\\n        model = keras.Model(inputs=[seq_data, seq_lengths], outputs=[dense])\\n\\n        model.compile(optimizer=tf.keras.optimizers.Adam(\\n            learning_rate=0.001),\\n            loss=tf.keras.backend.sparse_categorical_crossentropy\\n        )\\n\\n    batch_size = 1\\n    time_step = 1000\\n    signal_length = 1000\\n    sequences = np.random.rand(batch_size, time_step, 1)\\n    seq_lengths = np.array([signal_length])\\n    signal_mask = np.random.randint(5, size=(1, time_step))\\n\\n    dataset = tf.data.Dataset.from_tensor_slices(\\n        (sequences, seq_lengths,  signal_mask)).repeat(100).batch(1)\\\\\\n        .map(lambda a,b,c: ({\"seq_data\":a,\"seq_lengths\":b}, {\"signal_mask\":c}))\\n\\n    model.fit(dataset, epochs=1)\\n    \\nmain()\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-105>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample/model.py'"
     ]
    }
   ],
   "source": [
    "%%writefile sample/model.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def main():\n",
    "    mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "                        \n",
    "    with mirrored_strategy.scope():\n",
    "        seq_data = keras.Input(shape=(None, 1),  name=\"seq_data\")\n",
    "        seq_lengths = keras.Input(shape=(), name=\"seq_lengths\", dtype=tf.int32)\n",
    "\n",
    "        mask = keras.layers.Lambda(lambda x: tf.sequence_mask(x))(seq_lengths)\n",
    "        conv = layers.Conv1D(32, 3, strides=1, padding='same', activation='relu')(seq_data)\n",
    "        #rnn = layers.Bidirectional(layers.GRU(32, return_sequences=True))(conv,mask=mask)\n",
    "        rnn = layers.Bidirectional(layers.GRU(32, return_sequences=True))(conv)\n",
    "        dense = layers.Dense(5, name=\"signal_mask\")(rnn)\n",
    "        model = keras.Model(inputs=[seq_data, seq_lengths], outputs=[dense])\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=0.001),\n",
    "            loss=tf.keras.backend.sparse_categorical_crossentropy\n",
    "        )\n",
    "\n",
    "    batch_size = 1\n",
    "    time_step = 1000\n",
    "    signal_length = 1000\n",
    "    sequences = np.random.rand(batch_size, time_step, 1)\n",
    "    seq_lengths = np.array([signal_length])\n",
    "    signal_mask = np.random.randint(5, size=(1, time_step))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (sequences, seq_lengths,  signal_mask)).repeat(100).batch(1)\\\n",
    "        .map(lambda a,b,c: ({\"seq_data\":a,\"seq_lengths\":b}, {\"signal_mask\":c}))\n",
    "\n",
    "    model.fit(dataset, epochs=1)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  # Configure a master worker with 1 with K80 GPUs\n",
    "  masterType: n1-highcpu-16\n",
    "  masterConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 2\n",
    "      type: NVIDIA_TESLA_K80\n",
    "  # Configure 1 worker(s), each with 2 K80\n",
    "  workerCount: 1\n",
    "  workerType: n1-highcpu-16\n",
    "  workerConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 2\n",
    "      type: NVIDIA_TESLA_K80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: multi_cpu_fashion_minst_20200730_191020\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [multi_cpu_fashion_minst_20200730_191020] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe multi_cpu_fashion_minst_20200730_191020\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs multi_cpu_fashion_minst_20200730_191020\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"multi_cpu_fashion_minst_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://gp-ex \\\n",
    "  --package-path=sample \\\n",
    "  --module-name=sample.model \\\n",
    "  --runtime-version=2.1 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-west1 \\\n",
    "  --config config.yaml\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.Input(shape=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 2) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul:0' shape=(None, 2) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-92f17a7d2293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "y(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
